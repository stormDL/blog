---
title: CNN的常见问题(一)
catalog: true
tags:
  - 算法
  - 技术
categories: tech
mathjax: true
date: 2020-08-27 09:34:06
---

## 卷积层和全连接层的区别

- 局部连接
  1. 因为卷积核的尺寸一般远小于原图，输出层上的每个节点都只与输入层的部分节点连接
  2. 全连接输出层的每个节点与输入层的所有节点相连接
- 权值共享
  1. 卷积核的滑动机制使得输出层在不同位置的节点与输入层的连接权值都是一样的，即卷积核的值是不变的
  2. 全连接层的输出节点与输入层节点之间的权值都是不同的
- 结构化信息的包含
  1. 卷积神经网络的输出大致还保持着输入数据的结构
  2. 全连接层完全忽略了结构所带来的信息

## 卷积层的输出size、整体参数量、计算量

卷积核的width和height可能不一样所以卷积层的输出size我们分开计算宽和高:
$$
out_w = \lfloor \frac{w+2*p-1}{s} \rfloor + 1
$$

$$
out_h = \lfloor \frac{h+2*p-1}{s} \rfloor + 1
$$

其中$w$表示输入图像的width，$h$表示输入图像的height，$p$表示padding的取值即增加的空白数量,$s$表示步长，**向下取整是因为大家都默认这样处理**。

---

卷积层的参数量涉及到这些变量：

- 卷积核参数量$c^{i}\times k_h\times k_w$
- 卷积核个数$c^{o}$，即输出数据的通道个数

$$
nb_{param} = c^{i}\times k_h\times k_w \times c^{o}
$$

其中$c^{i}$表示输入数据的channel个数，$k_h$表示一个卷积核的height，$k_w$表示一个卷积核的width，$c^{o}$表示输出数据的通道个数

---

计算量由滑动窗内的参数量以及滑动的次数决定：

- 滑动次数就是输出层的$out_w\times out_h \times c^{o}$
- 滑动窗内的参数量就是$k_w \times k_h \times c^{i}$

$$
nb_{cal} = out_w\times out_h \times c^{o} \times k_w \times k_h \times c^{i}
$$

## 卷积层的感受野及其size计算

感受野是指对于输出层的某个点，在**卷积神经网络的原始输入数据上能影响到这个点的取值的区域**！

以 2 维卷积神经网络为例子，假设原始输入特征图的尺寸是$L_w\times L_h$，计算第i层的感受野size：

**若第i层是卷积层or池化层**，那么感受野区域的计算公式为：
$$
R_{w}^{i} = min(R_{w}^{i-1} + (k_{w}^{i}-1)\prod_{j=0}^{i-1}s_{w}^{j}, L_w)
$$
其中，$R_{w}^{i}$表示第i层的感受野width，$k_{w}^{i}$表示第i层的卷积核宽度，$s_{w}^{j}$表示第j层的步长


$$
R_{h}^{i} = min(R_{h}^{i-1} + (k_{h}^{i}-1)\prod_{j=0}^{i-1}s_{h}^{j}, L_h)
$$
其中，$R_{h}^{i}$表示第i层的感受野width，$k_{h}^{i}$表示第i层的卷积核宽度，$s_{h}^{j}$表示第j层的步长

特别的，有如下定义:
$$
\begin{equation}
    \left\{
    \begin{aligned}
        R_{e}^{0} & = & 1 \\
        s_{e}^{0} & = & 1 \\
    \end{aligned}
    \right.
\end{equation}
$$

> 上述公式咋一看可能会觉得莫名其妙，但是可以推导一下验证公式的正确性，是没有任何问题的

---

若第i层为激活层、批量归一化层，那么其感受野是不会变化的：
$$
R^{(i)} = R^{(i-1)}
$$

---

若第i层为全连接层，那么其感受野就是输入数据全域:
$$
R^{i} = L
$$
 